{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras import backend as K\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialización de los parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=6                           # for reproducibility \n",
    "np.random.seed(seed)\n",
    "\n",
    "w1 = np.random.normal(loc=0, scale=1, size=(3,2)) #Capa 1 afectada por capa 0\n",
    "w2 = np.random.normal(loc=0, scale=1, size=(3,)) #Capa 2 afectada por capa 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patrones de aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = 4 #Cantidad de patrones para entrenar\n",
    "x_train = np.zeros((ntrain, 3), dtype = np.float32) #Entradas\n",
    "y_train = np.zeros((ntrain, 1), dtype = np.float32) #Salidas\n",
    "\n",
    "x_train[0][0] = 1\n",
    "x_train[0][1] = 1\n",
    "y_train[0] = 1\n",
    "\n",
    "x_train[1][0] = 1\n",
    "x_train[1][1] = -1\n",
    "y_train[1] = -1\n",
    "\n",
    "x_train[2][0] = -1\n",
    "x_train[2][1] = 1\n",
    "y_train[2] = -1\n",
    "\n",
    "x_train[3][0] = -1\n",
    "x_train[3][1] = -1\n",
    "y_train[3] = 1\n",
    "\n",
    "#Neurona de bias en la capa de entrada\n",
    "for i in range(ntrain):\n",
    "    x_train[i][2] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y_esp, y_obt):\n",
    "    '''\n",
    "    Recibe el vector de patrones de salidas esperadas y obtenidas (escalares) y calcula el error cuadrático\n",
    "    '''\n",
    "    e = 0\n",
    "    for i in range(len(y_esp)):\n",
    "        for j in range(len(y_esp[0])):\n",
    "            e += (y_esp[i][j] - y_obt[i][j])**2\n",
    "    \n",
    "    e = 0.5*e\n",
    "\n",
    "    return e\n",
    "\n",
    "def g(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def g_pr(x):\n",
    "    y = 1 - np.tanh(x)**2\n",
    "    return y\n",
    "\n",
    "def v1_accuracy(y_true, y_pred):\n",
    "    return np.mean(K.mean(K.equal(y_true, K.round(y_pred)), axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables para el loop de aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 6 #Cantidad de realizaciones\n",
    "lrs = [0.01, 0.05, 0.1, 0.5, 1, 5] #learning rates\n",
    "epocas = 1000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectores para luego analizar el desempeño promedio de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.zeros(shape=(epocas, r)) #Accuracy de la neurona\n",
    "mse = np.zeros(shape=(epocas, r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop de aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(lrs)):\n",
    "    lr = lrs[i]\n",
    "\n",
    "    #Módulos de las correcciones\n",
    "    deltas1 = np.zeros(epocas) #Módulo del vector deltaW1\n",
    "    deltas2 = np.zeros(epocas)  #Módulo del vector deltaW2\n",
    "\n",
    "    #Salidas de la red para cada época\n",
    "    salidas = np.zeros((ntrain, 1), dtype = np.float32) #Salidas #Registro las salidas predichas y calculo accuracy\n",
    "\n",
    "\n",
    "    for k in range(epocas):\n",
    "        deltaW1 = np.zeros(shape=(3,2))\n",
    "        deltaW2 = np.zeros(shape=(3,))\n",
    "\n",
    "        for mu in range(ntrain):\n",
    "\n",
    "        #FORWARD PROPAGATION (entrada)\n",
    "            #Capa de entrada\n",
    "            c0 = x_train[mu]\n",
    "            # print(\"\\n\\nEntrada\")\n",
    "            # print(c0)\n",
    "\n",
    "            #Capa oculta\n",
    "            h1 = np.dot(c0,w1)\n",
    "            c1 = g(h1)\n",
    "            # print(\"\\nCapa oculta\")\n",
    "            # print(c0)\n",
    "            # print(w1)\n",
    "            # print(h1)\n",
    "            # print(c1)\n",
    "\n",
    "            #Capa de salida\n",
    "            h2 = np.dot(np.concatenate([c1, [c0[2]]]), w2)\n",
    "            c2 = g(h2) #output\n",
    "            salidas[mu] = c2\n",
    "            # print(\"\\nSalida\")\n",
    "            # print(np.concatenate([c1, [c0[2]]]))\n",
    "            # print(w2)\n",
    "            # print(h2)\n",
    "            # print(c2)\n",
    "\n",
    "\n",
    "        #BACK PROPAGATION (delta)    \n",
    "            delta2 = (y_train[mu] - c2)*g_pr(h2)\n",
    "            # print(\"\\nBack propagation\")\n",
    "            # print(delta2)\n",
    "            # print(w2[:-1]) \n",
    "            # print(g_pr(h1))\n",
    "\n",
    "            delta1 = delta2*w2[:-1]*g_pr(h1) #No tengo que backpropagar el delta a la neurona del bias (omite el último elemento de w2)\n",
    "            # print(delta1)\n",
    "            #break\n",
    "\n",
    "        #FORWARD PROPAGATION (correccion)\n",
    "            deltaW1 += lr * c0[:, np.newaxis] * delta1 #doy vuelta c0 para obtener el producto vectorial\n",
    "            # print(\"\\nCorrecciones 1\")\n",
    "            # print(lr)\n",
    "            # print(c0[:, np.newaxis])\n",
    "            # print(delta1)\n",
    "            # print(deltaW1)\n",
    "            #break\n",
    "\n",
    "            deltaW2 += lr * np.concatenate([c1, [c0[2]]]) * delta2\n",
    "            # print(\"\\nCorrecciones 2\")\n",
    "            # print(lr)\n",
    "            # print(np.concatenate([c1, [c0[2]]]))\n",
    "            # print(delta2)\n",
    "            # print(deltaW2)\n",
    "\n",
    "        w1 += deltaW1\n",
    "        w2 += deltaW2\n",
    "\n",
    "        deltas1[k] = np.linalg.norm(deltaW1)\n",
    "        deltas2[k] = np.linalg.norm(deltaW2)\n",
    "        mse[k, i] = MSE(y_train, salidas)\n",
    "        accuracy[k, i] = v1_accuracy(y_train, salidas)\n",
    "\n",
    "\n",
    "    # print(\"Matrices de pesos finales\")\n",
    "    # print(w1)\n",
    "    # print(w2)\n",
    "    # print(mse[-1, i])\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(lrs)):\n",
    "    plt.semilogy(range(1, epocas+1), mse[:,i], label = str(lrs[i]))\n",
    "\n",
    "plt.xlabel(\"Epoca\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardo datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mse_mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\IB\\7mo cuatri\\Redes neuronales\\Practicas\\Practica4\\Ejercicio1\\ej1-a-learning_rates.ipynb Cell 17\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/IB/7mo%20cuatri/Redes%20neuronales/Practicas/Practica4/Ejercicio1/ej1-a-learning_rates.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m f_out\u001b[39m.\u001b[39mwrite(\u001b[39m\"\u001b[39m\u001b[39mep loss loss_stdv acc acc_stdv\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/IB/7mo%20cuatri/Redes%20neuronales/Practicas/Practica4/Ejercicio1/ej1-a-learning_rates.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epocas):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/IB/7mo%20cuatri/Redes%20neuronales/Practicas/Practica4/Ejercicio1/ej1-a-learning_rates.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     f_out\u001b[39m.\u001b[39mwrite(\u001b[39mstr\u001b[39m(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(mse_mean[i]) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(mse_std[i]) \u001b[39m+\u001b[39m  \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(acc_mean[i]) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(acc_std[i]) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/IB/7mo%20cuatri/Redes%20neuronales/Practicas/Practica4/Ejercicio1/ej1-a-learning_rates.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m f_out\u001b[39m.\u001b[39mclose()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mse_mean' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"D:\\IB/7mo cuatri\\Redes neuronales\\Practicas\\Practica4\")\n",
    "f_out = open(\"Ejercicio1/1a.txt\", \"w\")\n",
    "f_out.write(\"ep loss loss_stdv acc acc_stdv\\n\")\n",
    "for i in range(epocas):\n",
    "    f_out.write(str(i+1) + \" \" + str(mse_mean[i]) + \" \" + str(mse_std[i]) +  \" \" + str(acc_mean[i]) + \" \" + str(acc_std[i]) + \"\\n\")\n",
    "f_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
